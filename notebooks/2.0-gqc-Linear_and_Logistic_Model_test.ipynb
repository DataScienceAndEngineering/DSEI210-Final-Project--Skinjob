{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear_and_Logistic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow"
      ],
      "metadata": {
        "id": "QalFRfHvQRvt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_labels = pd.read_csv('../content/drive/MyDrive/DSE_I2100/data/GroundTruth.csv')\n",
        "df_labels['image'] = df_labels['image'] +'.jpg'\n",
        "\n",
        "labels=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']\n",
        "label_list=[]\n",
        "for i in range (len(df_labels)):\n",
        "    row= list(df_labels.iloc[i])\n",
        "    del row[0]\n",
        "    index=np.argmax(row)\n",
        "    label=labels[index]\n",
        "    label_list.append(label)\n",
        "df_labels['label']= label_list\n",
        "df_labels=df_labels.drop(labels, axis=1)\n",
        "df_labels['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXtWfpp0QT-N",
        "outputId": "3000cb72-f0e3-4fd1-a9d0-4cc3d8d4bf98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NV       6705\n",
              "MEL      1113\n",
              "BKL      1099\n",
              "BCC       514\n",
              "AKIEC     327\n",
              "VASC      142\n",
              "DF        115\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tain_size=0.7\n",
        "valid_size = 0.1\n",
        "test_size = 0.2\n",
        "valid_test_split = valid_size / test_size\n",
        "\n",
        "train_df, valid_test_df = train_test_split(df_labels, train_size=tain_size, shuffle=True, random_state=42)\n",
        "valid_df, test_df = train_test_split(valid_test_df, train_size=valid_test_split, shuffle=True, random_state=42)\n",
        "\n",
        "print(' train_df length: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))\n",
        "print (train_df.head())\n",
        "print (train_df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqFGRWxeQcDB",
        "outputId": "163e5c30-4713-4668-fe46-4e2a1fdf759b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " train_df length:  7010   test_df length:  1503   valid_df length:  1502\n",
            "                 image label\n",
            "2399  ISIC_0026705.jpg    NV\n",
            "8246  ISIC_0032552.jpg   MEL\n",
            "8052  ISIC_0032358.jpg   BKL\n",
            "5840  ISIC_0030146.jpg    NV\n",
            "3540  ISIC_0027846.jpg   BCC\n",
            "NV       4686\n",
            "BKL       784\n",
            "MEL       758\n",
            "BCC       362\n",
            "AKIEC     235\n",
            "VASC      100\n",
            "DF         85\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sdir=r'../content/drive/MyDrive/DSE_I2100/data/images' # main directory where data is stored\n",
        "save_dir=r'./' # output directory where model will be saved\n",
        "subject='cancer' # part of the name of the saved model\n",
        "height=64  # image height\n",
        "width=64   # image width\n",
        "channels=3  # number of coloor channels\n",
        "batch_size=40  # model batch size for training and evaluation\n",
        "img_shape=(height, width, channels)\n",
        "img_size=(height, width)\n",
        "\n",
        "gen=ImageDataGenerator(rescale=1/255) # scale pixel between 0 and 1\n",
        "\n",
        "train_gen=gen.flow_from_dataframe( train_df, sdir, x_col='image', y_col='label', target_size=img_size, class_mode='categorical',\n",
        "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXsyj7cYQiF0",
        "outputId": "51e437d8-2a60-4b33-8d56-bb6ff3694fdd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7010 validated image filenames belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_gen=gen.flow_from_dataframe(valid_df, sdir, x_col='image', y_col='label', target_size=img_size, class_mode='categorical',\n",
        "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_E0AxetUwsC",
        "outputId": "3a45bd53-2b00-4fcf-9947-a3b90dd1c69b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1502 validated image filenames belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = tf.keras.Sequential([    \n",
        "   keras.layers.Flatten(input_shape=(height, width, channels)),                                                                 \n",
        "   keras.layers.Dense(7, activation = 'ReLU')                                 \n",
        "])\n",
        "linear_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "linear_model.fit(train_gen, epochs=8, steps_per_epoch= 7010 // batch_size,  validation_data=valid_gen, validation_steps= 1502 // batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfvlNgKgQnYq",
        "outputId": "bdacf505-fe09-49c7-a43c-cfa074d86c08"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "175/175 [==============================] - 109s 620ms/step - loss: 1.4627 - accuracy: 0.6653 - val_loss: 1.4626 - val_accuracy: 0.6662\n",
            "Epoch 2/8\n",
            "175/175 [==============================] - 112s 639ms/step - loss: 1.4517 - accuracy: 0.6687 - val_loss: 1.4538 - val_accuracy: 0.6682\n",
            "Epoch 3/8\n",
            "175/175 [==============================] - 107s 611ms/step - loss: 1.4542 - accuracy: 0.6681 - val_loss: 1.4597 - val_accuracy: 0.6669\n",
            "Epoch 4/8\n",
            "175/175 [==============================] - 111s 635ms/step - loss: 1.4529 - accuracy: 0.6684 - val_loss: 1.4597 - val_accuracy: 0.6669\n",
            "Epoch 5/8\n",
            "175/175 [==============================] - 108s 616ms/step - loss: 1.4548 - accuracy: 0.6680 - val_loss: 1.4656 - val_accuracy: 0.6655\n",
            "Epoch 6/8\n",
            "175/175 [==============================] - 106s 608ms/step - loss: 1.4536 - accuracy: 0.6683 - val_loss: 1.4626 - val_accuracy: 0.6662\n",
            "Epoch 7/8\n",
            "175/175 [==============================] - 107s 613ms/step - loss: 1.4536 - accuracy: 0.6683 - val_loss: 1.4567 - val_accuracy: 0.6676\n",
            "Epoch 8/8\n",
            "175/175 [==============================] - 106s 608ms/step - loss: 1.4523 - accuracy: 0.6686 - val_loss: 1.4656 - val_accuracy: 0.6655\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65c2053ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = tf.keras.Sequential([    \n",
        "   keras.layers.Flatten(input_shape=(height, width, channels)),                                                                 \n",
        "   keras.layers.Dense(7, activation = 'sigmoid')                                 \n",
        "])\n",
        "linear_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "linear_model.fit(train_gen, epochs=8, steps_per_epoch= 7010 // batch_size,  validation_data=valid_gen, validation_steps= 1502 // batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-UXP1YCVO9T",
        "outputId": "e3797c34-4a96-4838-f4fd-4d7fd91383cd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "175/175 [==============================] - 386s 2s/step - loss: 0.3229 - accuracy: 0.6462 - val_loss: 0.2435 - val_accuracy: 0.6453\n",
            "Epoch 2/8\n",
            "175/175 [==============================] - 107s 613ms/step - loss: 0.2550 - accuracy: 0.6516 - val_loss: 0.2535 - val_accuracy: 0.6169\n",
            "Epoch 3/8\n",
            "175/175 [==============================] - 114s 650ms/step - loss: 0.2694 - accuracy: 0.6512 - val_loss: 0.2424 - val_accuracy: 0.6378\n",
            "Epoch 4/8\n",
            "175/175 [==============================] - 107s 614ms/step - loss: 0.2502 - accuracy: 0.6558 - val_loss: 0.3746 - val_accuracy: 0.6655\n",
            "Epoch 5/8\n",
            "175/175 [==============================] - 106s 607ms/step - loss: 0.2537 - accuracy: 0.6610 - val_loss: 0.2719 - val_accuracy: 0.6426\n",
            "Epoch 6/8\n",
            "175/175 [==============================] - 107s 610ms/step - loss: 0.2446 - accuracy: 0.6666 - val_loss: 0.2265 - val_accuracy: 0.6703\n",
            "Epoch 7/8\n",
            "175/175 [==============================] - 106s 606ms/step - loss: 0.2486 - accuracy: 0.6657 - val_loss: 0.2418 - val_accuracy: 0.6507\n",
            "Epoch 8/8\n",
            "175/175 [==============================] - 113s 645ms/step - loss: 0.2432 - accuracy: 0.6687 - val_loss: 0.2783 - val_accuracy: 0.6426\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65c13c1b90>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}